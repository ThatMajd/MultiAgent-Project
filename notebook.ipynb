{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file called `.env`\n",
    "and in it put:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_API_KEY='...'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.environ['AZURE_OPENAI_API_KEY']\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "def debug(s, title=None):\n",
    "    if title:\n",
    "        print(f\"[*] {title}\")\n",
    "    print(f\"[*] {s}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT:\n",
    "Set production flag to True to use OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCTION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI production flag set to:  True\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"openai_azure\": {\n",
    "        \"api_key\": AZURE_OPENAI_API_KEY,\n",
    "        \"azure_deployment\": \"team1-gpt4o\", # The deployment name\n",
    "        \"azure_endpoint\": \"https://096290-oai.openai.azure.com\",\n",
    "        \"openai_api_version\": \"2023-05-15\",\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "}\n",
    "\n",
    "if PRODUCTION:\n",
    "    # Init openai\n",
    "    print(\"Using OpenAI production flag set to: \", PRODUCTION)\n",
    "    chat = AzureChatOpenAI(**config[\"openai_azure\"])\n",
    "else:\n",
    "    print(\"Using Gemini production flag set to: \", PRODUCTION)\n",
    "    chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Belgium is **Brussels**.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "# Example text completion function\n",
    "def generate_completion(user_input):\n",
    "    \"\"\"\n",
    "    Generates a completion using the Azure OpenAI Chat API via LangChain.\n",
    "    Args:\n",
    "    user_input (str): The input prompt from the user.\n",
    "    Returns:\n",
    "    str: The completion response from the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Render the prompt\n",
    "    formatted_prompt = prompt_template.format(input=user_input)\n",
    "    messages = [HumanMessage(content=formatted_prompt)]\n",
    "\n",
    "    # Generate response\n",
    "    response = chat(messages=messages)\n",
    "    return response.content\n",
    "\n",
    "generate_completion(\"What is the capital of Belguim?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Good for short and not nested structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // The name of the person\n",
      "\t\"age\": string  // The age of the person\n",
      "\t\"interests\": string  // A list of the person's interests\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"The name of the person\"),\n",
    "    ResponseSchema(name=\"age\", description=\"The age of the person\"),\n",
    "    ResponseSchema(name=\"interests\", description=\"A list of the person's interests\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex and nested structures used Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Define Pydantic models for your structure\n",
    "class Cravings(BaseModel):\n",
    "    type: str = Field(description=\"The type of food craved (e.g., dessert, snack, meal)\")\n",
    "    style: str = Field(description=\"The style of food preferred (e.g., light, rich, savory)\")\n",
    "    flavor: str = Field(description=\"The flavor profile preferred (e.g., fruity, chocolatey, spicy)\")\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    age: int = Field(description=\"User's age in years\")\n",
    "    weight: float = Field(description=\"User's weight in kg\")\n",
    "    height: float = Field(description=\"User's height in cm\")\n",
    "    calorie_limit: float = Field(description=\"Maximum calories allowed per meal/snack\")\n",
    "\n",
    "class UserPreferences(BaseModel):\n",
    "    cravings: Cravings\n",
    "    available_ingredients: List[str] = Field(description=\"List of ingredients the user has available\")\n",
    "    user_profile: UserProfile\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=UserPreferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Output of LLM is not str\n",
      "[*] Formatted Output before invoking LLM\n",
      "[*] \n",
      "    Extract and organize the information from the user's text into a structured format.\n",
      "    The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Cravings\": {\"properties\": {\"type\": {\"description\": \"The type of food craved (e.g., dessert, snack, meal)\", \"title\": \"Type\", \"type\": \"string\"}, \"style\": {\"description\": \"The style of food preferred (e.g., light, rich, savory)\", \"title\": \"Style\", \"type\": \"string\"}, \"flavor\": {\"description\": \"The flavor profile preferred (e.g., fruity, chocolatey, spicy)\", \"title\": \"Flavor\", \"type\": \"string\"}}, \"required\": [\"type\", \"style\", \"flavor\"], \"title\": \"Cravings\", \"type\": \"object\"}, \"UserProfile\": {\"properties\": {\"age\": {\"description\": \"User's age in years\", \"title\": \"Age\", \"type\": \"integer\"}, \"weight\": {\"description\": \"User's weight in kg\", \"title\": \"Weight\", \"type\": \"number\"}, \"height\": {\"description\": \"User's height in cm\", \"title\": \"Height\", \"type\": \"number\"}, \"calorie_limit\": {\"description\": \"Maximum calories allowed per meal/snack\", \"title\": \"Calorie Limit\", \"type\": \"number\"}}, \"required\": [\"age\", \"weight\", \"height\", \"calorie_limit\"], \"title\": \"UserProfile\", \"type\": \"object\"}}, \"properties\": {\"cravings\": {\"$ref\": \"#/$defs/Cravings\"}, \"available_ingredients\": {\"description\": \"List of ingredients the user has available\", \"items\": {\"type\": \"string\"}, \"title\": \"Available Ingredients\", \"type\": \"array\"}, \"user_profile\": {\"$ref\": \"#/$defs/UserProfile\"}}, \"required\": [\"cravings\", \"available_ingredients\", \"user_profile\"]}\n",
      "```\n",
      "    \n",
      "    User Text: \n",
      "I am 28 years old, weigh about 65kg and I'm 170cm tall. \n",
      "I'm trying to watch my calories, so I want to stay under 300 calories for this snack.\n",
      "I'm really craving something fruity and light for dessert.\n",
      "I have some strawberries and yogurt in my fridge that I could use.\n",
      "\n",
      "    \n",
      "    Parse the above text to extract all relevant information about the user's cravings, available ingredients, and profile.\n",
      "    \n",
      "[*] LLM Output\n",
      "[*] ```json\n",
      "{\n",
      "  \"cravings\": {\n",
      "    \"type\": \"dessert\",\n",
      "    \"style\": \"light\",\n",
      "    \"flavor\": \"fruity\"\n",
      "  },\n",
      "  \"available_ingredients\": [\n",
      "    \"strawberries\",\n",
      "    \"yogurt\"\n",
      "  ],\n",
      "  \"user_profile\": {\n",
      "    \"age\": 28,\n",
      "    \"weight\": 65,\n",
      "    \"height\": 170,\n",
      "    \"calorie_limit\": 300\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def generate_struct(user_text, instructions, _debug=False):\n",
    "    # Update the prompt template to guide the LLM to parse user text\n",
    "    prompt_template = \\\n",
    "    \"\"\"\n",
    "    Extract and organize the information from the user's text into a structured format.\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Text: {user_text}\n",
    "    \n",
    "    Parse the above text to extract all relevant information about the user's cravings, available ingredients, and profile.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"user_text\"],\n",
    "        partial_variables={\"format_instructions\": instructions},\n",
    "        template=prompt_template\n",
    "    )\n",
    "    \n",
    "    formatted_prompt = prompt.format(user_text=user_text)\n",
    "    \n",
    "    llm_output = chat.invoke(formatted_prompt)\n",
    "    \n",
    "    if not isinstance(llm_output, str):\n",
    "        if _debug:\n",
    "            debug(\"Output of LLM is not str\") \n",
    "        llm_output = llm_output.text()\n",
    "    \n",
    "    if _debug:\n",
    "        debug(formatted_prompt, \"Formatted Output before invoking LLM\")\n",
    "        debug(llm_output, \"LLM Output\")\n",
    "    \n",
    "    try:\n",
    "        return parser.parse(llm_output)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"LLM may have returned unstructured output and cannot be parsed: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "user_text = \"\"\"\n",
    "I am 28 years old, weigh about 65kg and I'm 170cm tall. \n",
    "I'm trying to watch my calories, so I want to stay under 300 calories for this snack.\n",
    "I'm really craving something fruity and light for dessert.\n",
    "I have some strawberries and yogurt in my fridge that I could use.\n",
    "\"\"\"\n",
    "\n",
    "instructions = parser.get_format_instructions()\n",
    "\n",
    "out = generate_struct(user_text, instructions, _debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'available_ingredients': ['strawberries', 'yogurt'],\n",
      " 'cravings': {'flavor': 'fruity', 'style': 'light', 'type': 'dessert'},\n",
      " 'user_profile': {'age': 28,\n",
      "                  'calorie_limit': 300.0,\n",
      "                  'height': 170.0,\n",
      "                  'weight': 65.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9f/_6775r3x22z0p4kb6_fn2xmr0000gn/T/ipykernel_27249/2954805604.py:16: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  pprint(out.dict())\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "example_output = {\n",
    "    \"cravings\": {\n",
    "        \"type\": \"desert\",\n",
    "        \"style\": \"light\",\n",
    "        \"flavor\": \"fruity\"\n",
    "    },\n",
    "    \"available_ingredients\": [\"strawberries\", \"yogurt\"],\n",
    "    \"user_profile\": {\n",
    "        \"age\": 28,\n",
    "        \"weight\": 65,\n",
    "        \"height\": 170,\n",
    "        \"calorie_limit\": 300\n",
    "    }\n",
    "}\n",
    "pprint(out.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
